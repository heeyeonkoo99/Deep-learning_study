# 0. Preparation
*-전반적인 딥러닝의 개념을 찾아본다.*  
*-계속 필요한 내용을 업데이트할 예정이다.*

##### 

* 우선 딥러닝하면 빼놓고 볼수 없는 CNN에 관해 알아본다. CNN은 Convolutional Neural Network의 약자이며 합성곱신경망을 의미한다.  

* CNN 기원) David H. Hubel과 Torsten Wiesel은 1958년과 1959년에 시각 피질의 구조에 대한 결정적인 통찰을 제공한 고양이 실험을 수행했다. 이들은 시각 피질 안의 많은 뉴런이 작은 local receptive   
field(국부 수용영역)을 가진다는 것을 보였으며, 이것은 뉴런들이 시야의 일부 범위 안에 있는 시각 자극에만 반응을 한다는 의미이다. 뉴런의 수용영역(receptive field)들은 서로 겹칠수 있으며,   
이렇게 겹쳐진 수용영역들이 전체 시야를 이루게 된다. 추가적으로 어떤 뉴런은 수직선의 이미지에만 반응하고, 다른 뉴런은 다른 각도의 선에 반응하는 뉴런이 있을 뿐만아니라, 어떤 뉴런은 큰 수용영역을 
가져 저수준의 패턴(edge, blob 등)이 조합되어 복잡한 패턴(texture, object)에 반응하다는 것을 알게 되었다. 이러한 관찰을 통해 고수준의 뉴런이 이웃한 저수준의 뉴런의 출력에 기반한다는 아이디어를
생각해 냈다. 이러한 아이디어로부터 CNN이 나온것이다!

* CNN 알고리즘 동작 방식) CNN은 Convolution과 Pooling을 반복해서 데이터량을 줄이고 인위적인 왜곡으로 분류가 일어나도록 신경망을 생성한다.  
일반적으로 모델에서 특징추출과 분류를 하는데, 특징추출은 Convolution으로 하고 분류는 신경망으로 한다. 전형적인 CNN은 Convolution Layer과 Max Pooling Layer를 반복적으로 쌓아서 데이터의   
특징을 추출하는 부분과 Fully-Connected Layer를 구성하고 마지막 출력층에 Softmax를 적용해서 분류를 합니다.   
 **Convolution Layer,Max Pooling Layer 반복-> Fully-connected Layer-> Softmax**

* CNN 구조) 완전연결(fully connected)계층과는 달리 앞단계에선 합성곱층(convolutional layer)과 풀링층(pooling layer)으로 구성되어있다.   
=> 완전연결에서의 '데이터의 형상이 무시되는 문제'가 해결되는것이다. 합성곱층은 CNN에서 가장 중요한 구성요소이며, 2.1의 완전연결 계층과는 달리 합성곱층(convolutional layer)은 아래의 그림과 같이  
입력 데이터의 형상을 유지한다. 3차원의 이미지 그대로 입력층에 입력받으며, 출력 또한 3차원 데이터로 출력하여 다음 계층(layer)으로 전달하기 때문에 CNN에서는 이미지 데이터처럼 형상을 가지는   
데이터를 제대로 학습할 가능성이 높다고 할 수 있다.  
![https://camo.githubusercontent.com/fea95a2bfb69f9c0f1f883e1c877f2b013da516de413aabc93c53c6ed507d156/687474703a2f2f6269742e6c792f316e6d68476a45](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMO9SC%2FbtqzjKwR98S%2FAsKHOEOHeIO3Ad5vcCippk%2Fimg.png)











-------
# References  
https://blog.naver.com/rndus0819 (내 블로그..ㅎㅎ)  
https://muzukphysics.tistory.com/195
